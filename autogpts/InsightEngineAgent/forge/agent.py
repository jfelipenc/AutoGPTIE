import json
import pprint
import datetime
import time
import re
import uuid

import tiktoken

from forge.sdk import (
    Agent,
    AgentDB,
    AgentVectorDB,
    Step,
    StepRequestBody,
    Workspace,
    ForgeLogger,
    Task,
    TaskRequestBody,
    PromptEngine,
    chat_completion_request,
)

LOG = ForgeLogger(__name__)


class ForgeAgent(Agent):
    def __init__(self, database: AgentDB, vectordb: AgentVectorDB, workspace: Workspace):
        """
        The database is used to store tasks, steps and artifact metadata. The workspace is used to
        store artifacts. The workspace is a directory on the file system.

        Feel free to create subclasses of the database and workspace to implement your own storage
        """
        super().__init__(database, vectordb, workspace)

    async def format_step_request(self, task: str, task_id: str, is_last: bool):
        """
        This method is used to create a step request from a task. The step request is then used to
        create a step.
        """
        step_request = StepRequestBody(
            input=task,
            additional_input={}
        )
        step = await self.create_step(task_id=task_id, step_request=step_request, is_last=is_last)
        return step
    
    async def parse_plan_to_steps(self, planned_steps: str, task_id: str):
        """
        This method parses the plan generated by the LLM planning agent into steps that are then created
        and later used to execute the task.
        """
        data = planned_steps
        original_task = await self.db.get_task(task_id)
        original_task_input = original_task.input
        
        if 'subtasks' in data:
            for subtask in data['subtasks']:
                await self.parse_plan_to_steps(subtask, task_id)
                
        if 'task' in data:
            await self.format_step_request(data['task'], task_id, is_last=True if data['task'] == original_task_input else False)
            
    async def create_task(self, task_request: TaskRequestBody) -> Task:
        """
        The agent protocol, which is the core of the Forge, works by creating a task and then
        executing steps for that task. This method is called when the agent is asked to create
        a task.
        """
        task = await super().create_task(task_request)
        LOG.info(
            f"ðŸ“¦ Task created: {task.task_id} input: {task.input[:40]}{'...' if len(task.input) > 40 else ''}"
        )
        
        # loads the prompt engine with gpt-3.5-turbo templates
        prompt_engine = PromptEngine("gpt-3.5-turbo")
        
        # planner response format
        planner_format = prompt_engine.load_prompt('plan-system-format')
        # instructions format
        task_plan_kwargs = {
            "date": str(datetime.date.today()),
            "task": task.input,
            "abilities": self.abilities.list_abilities_for_prompt()
        }
        task_plan = prompt_engine.load_prompt('task-plan-step', **task_plan_kwargs)
        messages = [
            {"role": "system", "content": planner_format},
            {"role": "user", "content": task_plan}
        ]
        
        # Creating steps from LLM planning agent
        planned_steps = await self.make_chat_completion(messages)
        
        await self.parse_plan_to_steps(planned_steps, task.task_id)
        #LOG.warning(f"Planned execution: {pprint.pformat(planned_steps)}")
        return task
    
    async def create_step(self, task_id: str, step_request: dict, is_last: bool = False) -> Step:
        step = await self.db.create_step(
            task_id=task_id, input=step_request, is_last=is_last
        )
        
        # Create step in vector database
        await self.vectordb.create_step(
            step_id=step.step_id,
            step_name=step.name,
            step_input=step.input,
            step_additional_input=str(step_request.additional_input),
            task_id=task_id,
            created_at=step.created_at.isoformat("T")+"Z"
        )
        LOG.info("Created step for task: " + step.input + " with id " + step.step_id)
        return step
        
    async def check_and_trim_message(self, message: str) -> str:
        enc = tiktoken.encoding_for_model('gpt-3.5-turbo')
        num_tokens = len(enc.encode(message))
        if num_tokens >= 4097:
            excess = num_tokens - 4097
            while num_tokens >= 4097:
                split_by = int(excess / 3)
                message = message[:split_by]
        return message
    
    async def make_chat_completion(self, messages: list) -> dict:
        answer = {}
        try:
            # define the parameters for chat completion request
            chat_completion_kwargs = {
                "messages": messages,
                "model": "gpt-3.5-turbo",
            }
            # make chat completion request and parse response
            chat_response = await chat_completion_request(**chat_completion_kwargs)
            answer = json.loads(chat_response["choices"][0]["message"]["content"])
            # Logs the answer
            LOG.info(f"Answer: {pprint.pformat(answer)}")
        except json.JSONDecodeError as e:
            # Handling JSON Decoding errors
            LOG.error(f"""Unable to decode chat response: {chat_response}
                      failed with error {e}""")
            answer = None
        except Exception as e:
            # Handling other exceptions
            LOG.error(f"Unable to generate chat response: {e}")
            answer = None
            
        return answer
    
    async def adding_substep_output(self,
                                    step_output_thought: dict,
                                    step_output_value: dict,
                                    step_output_type: str,
                                    step_id: str
                                    ):
        
        output_values = [str(value) for key, value in step_output_value.items()]
        output_thoughts = [str(value) for key, value in step_output_thought.items()]
        LOG.info("Creating output artifact on vector database...")
        try:
            await self.vectordb.create_step_output(
                step_output_id=str(uuid.uuid4()),
                output_thought=output_thoughts,
                output_value=output_values,
                output_type=step_output_type,
                step_id=step_id,
            )
        except Exception as e:
            LOG.warning(f"Failed creating output artifact on vector database due to {e}")
    
    async def execute_substep(self, 
                              task_id: str,
                              step: Step,
                              error_info: str,
                              previous_step_id: str = "") -> [Step, str]:
        LOG.info(f"""
                 Executing step id: {step.step_id}:
                    input: {step.input}
                    additional_input: {step.additional_input}
                    previous_step_id: {previous_step_id if previous_step_id != "" else "None"}
                {'Last execution error:'+ error_info if error_info != '' else ''}
                 """)
        
        prompt_engine = PromptEngine("gpt-3.5-turbo")

        # fills error information
        if error_info != "":
            step.additional_input["error_info"] = error_info
            
        # adds previous step execution output
        if previous_step_id != "":
            print("Awaiting for output from previous step...")
            step.additional_input["previous_step_output"] = await self.vectordb.get_output_with_stepid(previous_step_id)
            print("Output from previous step received.")
            
        # creates prompt for response format
        system_prompt = prompt_engine.load_prompt("system-format")
        
        # specify task parameters
        task_kwargs = {
            "date": str(datetime.date.today()),
            "task": step.input,
            "additional_input": step.additional_input,
            "error_info": error_info if error_info != "" else "",
            "abilities": self.abilities.list_abilities_for_prompt(),
        }
        
        # load task prompt with parameters
        task_prompt = prompt_engine.load_prompt("task-step", **task_kwargs)
        
        # messages list
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": await self.check_and_trim_message(task_prompt)}
        ]
        
        # Chat completion request
        answer = await self.make_chat_completion(messages)
        if answer == None:
            answer = await self.make_chat_completion(messages)
        
        # extracts the ability required to execute the step
        try:
            # selects ability to run
            print("Extracting ability to run...")
            ability = answer["ability"]
            
            # run the ability and get the output
            output = await self.abilities.run_ability(
                task_id, ability["name"], **ability["args"]
            )
            output_type = str(type(output))
            output = {'output': output}

            # update the step with the output of answer
            step.output = answer
            
            LOG.info(f"Finished executing step id:{step.step_id}. Updating status...")
            step.status = "completed"
            await self.db.update_step(task_id=task_id, step_id=step.step_id, status=step.status)
            
            # Creating object in database for step output
            await self.adding_substep_output(
                step_output_thought=step.output,
                step_output_value=output,
                step_output_type=output_type,
                step_id=step.step_id
            )
            error_info = ""
            return step, ""
        except Exception as e:
            print(f"Error when executing step id:{step.step_id}. Error information: {e}")
            error_info = str(e)
            return step, error_info
    
    async def execute_step(self, task_id: str, step_request: StepRequestBody) -> Step:
        # Get task to access task_input
        task = await self.db.get_task(task_id)
        steps = await self.db.list_steps(task_id)
        
        previous_step_id = ""
        steps_remaining = []
        for step in steps[0]:
            if step.status._value_ != 'completed' and step.status._value_ != 'failed':
                steps_remaining.append(step)
            elif step.status._value_ == 'completed':
                previous_step_id = step.step_id
        current_step = steps_remaining[0]
        
        successful = False
        n_exec = 0
        error_info = ""
        
        while not successful and n_exec < 3:
            step, error_info = await self.execute_substep(
                task_id=task_id,
                step=current_step,
                error_info=error_info,
                previous_step_id=previous_step_id
            )
            
            if error_info != "":
                n_exec += 1
            else:
                successful = True
        
        #TODO: if step fails, either revert to previous step (done) or reassess plan
        if n_exec == 3 and not successful:
            LOG.error(f"Failed execution of step id {step.step_id}. Error information: {error_info}.\n")
            step = await self.db.update_step(task_id, previous_step_id, status="created")
            return step
        
        if successful and step.is_last:
            #TODO: implement if step is last, delete all temporary tables
            pass
            
        return step
    